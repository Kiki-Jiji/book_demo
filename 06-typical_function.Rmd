
# A template function using futile logger for reading data in (data validation in QA)

The previous chapter covered how to write functions in R. This chapter covers a template function for reading in data and validating the data. You will be able to copy and paste the template and write your own functions and data checks. We will be covering data validation using the `futile.logger` package.            

## Data Validation function 

This function will have 5 main steps

* the documentation (covered in chapter 5)
* the function opening and arguments
* the futile logger setup
* data validation checks
* your code

Before we work on anything we should create a new branch and move onto it- this is covered in chapter 4. 

## Futile.Logger 

Quality Assurance is fundamental to the production of statistics. `futile.logger` is a package in R that allows us to easily validate the data that is ingested into out pipeline. Almost any Quality Assurance practice that you manually do can be implemented and automated in R using this package, such as:

* check for missing values
* check for unusual values (negative values in an age column)
* check 

We will include two arguments from `futile.logger` in the function setup. The documentation for [futile.logger](https://cran.r-project.org/web/packages/futile.logger/futile.logger.pdf) is available. 


### `log_level`   

There are multiple log levels available which ranges from TRACE to FATAL. The levels form a hierarchy that not only indicate the severity of the message but also when it should be displayed. This is controlled by the threshold, which only allows messages with a severity greater than or equal to the threshold to be displayed.

When futile.logger is loaded, the default log level is INFO. To change the logging threshold use the futile.threshold function. The available thresholds are the same as the log levels: TRACE, DEBUG, INFO, WARN, ERROR, FATAL. Choose the threshold that you want to see and all messages of that severity and higher will display.

With this simple mechanism you can add log statements in your code and control the display of the messages by simply changing the logging threshold. Hence for development keep the threshold on INFO, for debugging change to TRACE, and for production set to WARN.

We will demonstrate log messages with numerous functions latter in the chapter. 

### `log_appender`

An appender defines where a log message goes. This allows a log record to be kept providing a QA validation record. There are two appenders provided with `futile.logger`.   

* appender.console()
* appender.file(file name)

Appending to the console will print the log messages to the R studio console, allowing you to easily view the log messages as you run the functions. Logging to a file is useful for keeping a record.We will demonstrate both of these later.

This is meant as an introduction to error logging with `futile.logger` not a comprehensive guide. A great source is chapter 12 of the [Rap Companion](https://ukgovdatascience.github.io/rap_companion/qa-data.html) and this blog post from the package author also gives a good overview [Better logging in R](https://www.r-bloggers.com/better-logging-in-r-aka-futile-logger-1-3-0-released/) 

We will now write a function called read_data that will read in data from an excel spreadsheet, validate the data and preform a basic transformation of the data. This will serve as a template. You can copy and paste the code and change any section to make it more relevant for you.   

## The documentation 

To start you can copy and paste the following section. 

```
#'@title read_data
#' 
#'@description this function reads in data 
#' 
#'@details 
#' 
#'@param x This is a file path of the excel spreadsheet
#'
#'@param log_level This parameter will print messages which log the status of your function. These are
#'written from least to most serious: TRACE, DEBUG, INFO, WARN, ERROR, FATAL. The default level is INFO.
#'See \code{?flog.threshold()} for additional details.
#' 
#'@param log_appender This paramater sets the default so that the log is printed to the "console". #'Alternatively you can provide a character string to specify a filename to also write to. See
#'for additional details \code{?futile.logger::appender.file()}.
#'
#'@examples data <- read_data("file.path", log_level = futile.logger::WARN, log_appender = "console")
#'    
#'@export

```
This will be you documentation. You will at some point want to expand on the documentation, such as adding more of a description and details. You can see from `@param` that our function will have three arguments. The first is a file path that will indicate where the excel file is. The second is is the log_level, and the third is the log_appender. 

## The function Start

The function now need to be started, you can copy and paste this as well. 

```
read_data <- function(x, log_level = futile.logger::WARN, log_appender = "console") { 

}

```

This set's up the function. Everything need to be written within these braces. x is the filepath which will be passed to the function. The `log_level` has been provided with a default of WARN so that the function can be run without specifying a `log_level`. This can be changed to TRACE by running the function with `log_level = futile.logger::FATAL` as a argument, as provided in the documentation.

The log messages are by default outputted to the console. If a file name is given in the function call such as `log_appender= "QA_log_JAN19.txt"` then a new file called "QA_log_JAN19.text" will be created in the current directory containing the log messages according to the `log_level`. 

## `futile.logger` setup

The following code is needed for for the `futile.logger` arguments to work. But before we put the code we will want to read our data into R studio. The reason for this is that we are unable to preform data validation on a file path, we need to read the data into R and create a data.frame on which we can create log messages. For an excel spreadsheet this function might be:

``` 
test_data <- readxl::read_excel(x)
```

Inside the function there will now be a data frame called data containing the excel spreadsheet. Read the `read_excel` [documentation](https://www.rdocumentation.org/packages/readxl/versions/0.1.1/topics/read_excel) for additional arguments. 

The following code sets up futile logger. You can copy and paste the code block. The comments are not necessary but are helpful, but you can delete them if you wish to make your code cleaner, the information should also be in the function description. As I said before, all code needs to be inside the curly braces `{ }`.

```
# The following code now sets the flog threshold to the log_level defined in the 2nd argument of the function above
  
  futile.logger::flog.threshold(log_level)
  
  # This could be changed so that every detail is printed (not only errors and warnings). Do this by setting log_level argument to futile.logger::TRACE for full info.
  
  # Now, we create an option of printing and storing results from the checks in somewhere other than the console. Below we are saying
  # that if the log_appender argument is not set to console (and set to a file name) then R will create a file to store the information and outputs from checks. 
  
  if(log_appender != "console")
  {
    futile.logger::flog.appender(futile.logger::appender.file(log_appender))
  }
```
Now that `futile.logger` is set up we can run data validation on the incoming data. There are many way to achieve this in `futile.logger`. You will not be able to copy and paste this step as this will depend on rte data validation needed for your data. An example block of code shows some examples. 

First we can use `futile.logger::flog.info("")` to write a statement. This is useful for the QA logs. There are a number of different scales such as:

```
flog.info("My first log statement with futile.logger")
flog.warn("This statement has higher severity")
flog.fatal("This one is really scary")
```

Once the function is built you can experiment with setting the log to different levels and can see how this affects what is reported back. Below is an example with a start and end log, and one check. The `flog.info` tells us that the QA checks are starting, and if they are all passes then we will get a log saying ...passed. 

There is only one check but many more can be added between the checks started and checks ended comments. This is a basic check that examines whether the data frame has the expected number of columns, in this case 10. If it does not then it will print the message x must have 10 columns, and then carry on the function. This lets you know that thee data is not of the structure you expected but does not stop the function, as you may be aware of this and do not mind, however if you are not aware then this will let you know. If you do not understand this if statement then it would be useful spending some time on this.  
 

```
# Checks

futile.logger::flog.info("Quality Assurance of the pipeline")
  
# Intergrity checks on incoming data
# Check the structure of the data.frame is as expected
# checks started
  
futile.logger::flog.debug("Checking x has the expected number of columns")
if (!length(colnames(x)) == 10)
{
  futile.logger::flog.error("x must have 10 columns", x, capture = TRUE)
}
  
# checks ended

futile.logger::flog.info("...passed")
```

The checks necessary will depend on your data. If for example you are using age data, then you may want to checks for negative values which is not possible. The following example includes a stop, so that if the check fails the function stops. This is important for when a check failing is important enough that the process should not continue until the error is fixed. 

You can think of these checks as modular, adding as many as necessary. These might in fact constitute the majority of your code

This is an example of a check for missing values with a stop. The function `anyNA` is called on X, which would be your data frame. If the condition is true, that there are NA's, then the stop is initiated with a message telling you why the function has stopped. 

```
futile.logger::flog.debug("Checking for missing values")
    if(anyNA(x)) { 
      stop("There must not be missing values")
    }

```
## Your Code 

This section will include the R code to produce the output. In the case of a function that reads in the data, validates and the transforms the data into a useful form then this setion will be the transforming step (as we have already read in the data and validated). This step might be writing the code from scratch but it is often easier to have your working code already written in a script. You could open a new scipt and write the code you need, running through it to check that it works. Once you have the code working it is easy to modify it to run in a function. For example, the following code using an built in database mtcars. It then filter out any car with a `carb` less than 1, it then groups these by `cyl` and summarises the results. This script uses the package `dplyr`. 

``` {r, warnings = FALSE} 
library(dplyr)

x = datasets::mtcars

  a <- filter(x , carb > 1)
  b <- group_by(a, cyl)
  c <- summarise(b, Avg_mpg = mean(mpg))
  print(c)
```

To convert we need to change the `library()` call, and instead put the package that we need as an import. This is done in the descrption as previsously descrbied. 

```
#' @import dplyr
```
We would not use the inbuilt data, but the dataframe that we have read in earlier. Looking back we called this `test_data` so we chnage the function to instead of taking x, to take the object `test_data`. And we don't need to print the c object, but in a function we would want to `return(c)` instead. It is good pratcie to name the intermediate objects with informative names, letters are used for simplicity. You may also want to comment the code as you go. This helps you understand what you are doing, helps others who examine your code, and helps your future self who will have forgotten exactly what you wnated the code to do. You can format the comments as you wish (as long as each line starts with a #) but it will be easier if you use a stanard form, e.g. a blank line between each line of code, but no line between comments and code. Finally in a package we want to state the package of each function. This is good pratcie, and makes it far easiere to understand where your functions come from. In future when you get a package dependicy issue this will be very helpful. The nomenclature is `package::function` such as `dplyr::filter`. You 

```
# First we filter the data to get rud of any car with a carb less than 1
 a <- dplyr::filter(test_data , carb > 1)
 
# This groups by cyl and then summarises the result by the three levels of cyl (Number of cylinders) which #is 4 & 6  & 8
  b <- dplyr::group_by(a, cyl)
  c <- dplyr::summarise(b, Avg_mpg = mean(mpg))
 
 return(c)
}
```
You will also notice that the code chunks ends with }, as this is the end of the function! The whole function is shown below. I have changed the data source, from a excel to the inbuilt mtcars data frame, this allows you to use the code below as an example if you wish. if you have follwered the package set up and use the bewlow code you will have a working package with one function, in this case called read_data. 

```
#'@title read_data
#' 
#'@description this function reads in data 
#' 
#'@details 
#'
#'@param log_level This parameter will print messages which log the status of your function. These are
#'written from least to most serious: TRACE, DEBUG, INFO, WARN, ERROR, FATAL. The default level is INFO.
#'See \code{?flog.threshold()} for additional details.
#' 
#'@param log_appender This paramater sets the default so that the log is printed to the "console". #'Alternatively you can provide a character string to specify a filename to also write to. See
#'for additional details \code{?futile.logger::appender.file()}.
#'
#'@examples data <- read_data(log_level = futile.logger::WARN, log_appender = "console")
#'@import dplyr
#'
#'@export

read_data <- function(log_level = futile.logger::WARN, log_appender = "console") { 

test_data <- datasets::mtcars

# The following code now sets the flog threshold to the log_level defined in the 2nd argument of the function above
  
  futile.logger::flog.threshold(log_level)
  
  # This could be changed so that every detail is printed (not only errors and warnings). Do this by setting log_level argument to futile.logger::TRACE for full info.
  
  # Now, we create an option of printing and storing results from the checks in somewhere other than the console. Below we are saying
  # that if the log_appender argument is not set to console (and set to a file name) then R will create a file to store the information and outputs from checks. 
  
  if(log_appender != "console")
  {
    futile.logger::flog.appender(futile.logger::appender.file(log_appender))
  }

# Checks

futile.logger::flog.info("Quality Assurance of the pipeline")
  
# Intergrity checks on incoming data
# Check the structure of the data.frame is as expected
# checks started
  
futile.logger::flog.debug("Checking x has the expected number of columns")
if (!length(colnames(x)) == 10)
{
  futile.logger::flog.error("x must have 11 columns", x, capture = TRUE)
}
  
futile.logger::flog.debug("Checking for missing values")
    if(anyNA(x)) { 
      stop("There must not be missing values")
    }

futile.logger::flog.info("...passed")

# checks ended


# First we filter the data to get rud of any car with a carb less than 1
 a <- dplyr::filter(test_data , carb > 1)
 
# This groups by cyl and then summarises the result by the three levels of cyl (Number of cylinders) which #is 4 & 6  & 8
  b <- dplyr::group_by(a, cyl)
  c <- dplyr::summarise(b, Avg_mpg = mean(mpg))
 
 return(c)

}
```


